{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarcasm Detector\n",
    "\n",
    "Sometimes sarcasm is hard to detect, because it's a non-literal use of language and is context dependent. If there exists an intelligent machine learning model that knows sarcasm very well, humans can forever be saved from future misunderstandings and embarrassment.\n",
    "\n",
    "Since sarcasm is very context dependent, collecting the \"correct\" data is intractable. Principle of inferability states that speakers only use sarcasm if they can be sure it will be understood by the audience. However, it's interesting to note that sarcasm is still used in social media even when the audience is so large and unfamiliar. In the virtual world, speakers instead use indicators, such as Twitter hashtags, to convey what they infer.\n",
    "\n",
    "This is an implementation of [\"Contextualized Sarcasm Detection on Twitter\"](http://www.cs.cmu.edu/~nasmith/papers/bamman+smith.icwsm15.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For features, I considered both linguistic and contextual information:\n",
    "- number of intensifiers, undertones, and vowel excluded spellings (linguistic)\n",
    "- number of author's followers and posts, duration on Twitter, account verification and timezone (contextual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ \"num_intensifiers\", \"num_downtoners\", \"num_no_vowels\", \"verified\", \"num_followers\", \"num_statuses\", \"since_created\", \"time_zone\" ]\n",
    "\n",
    "def is_categorical(column):\n",
    "    return column == \"verified\" or column == \"time_zone\"\n",
    "\n",
    "num_intensifiers = tf.feature_column.numeric_column(columns[0])\n",
    "num_downtoners = tf.feature_column.numeric_column(columns[1])\n",
    "num_no_vowels = tf.feature_column.numeric_column(columns[2])\n",
    "verified = tf.feature_column.categorical_column_with_vocabulary_list(columns[3], ['True', 'False'])\n",
    "num_followers = tf.feature_column.numeric_column(columns[4])\n",
    "num_statuses = tf.feature_column.numeric_column(columns[5])\n",
    "since_created = tf.feature_column.numeric_column(columns[6])\n",
    "time_zone = tf.feature_column.categorical_column_with_hash_bucket(columns[7], hash_bucket_size=1000)\n",
    "\n",
    "tf_columns = [ num_intensifiers, num_downtoners, num_no_vowels, verified, num_followers, num_statuses, since_created, time_zone ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, I decided to use logistic regression on streams of live tweets, using presence and absence of the hashtag \"#sarcasm\" to differentiate for learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': '/tmp/tmptOzMhV', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(\n",
    "    feature_columns=tf_columns,\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=1.0,\n",
    "        l2_regularization_strength=1.0),\n",
    "    model_dir=tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = {}\n",
    "training_labels = []\n",
    "for column in columns:\n",
    "    training_set.update({column: []})\n",
    "    \n",
    "f = open('tweets.csv', 'r')\n",
    "f.readline()\n",
    "for line in f:\n",
    "    data = line.rstrip().split('\\t')\n",
    "    training_labels.append(data[-1] == 'True')\n",
    "    for i in range(len(data) - 1):\n",
    "        training_set[columns[i]].append(data[i] if is_categorical(columns[i]) else float(data[i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(d, l):\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={k: np.array(v) for k, v in d.items()},\n",
    "        y=np.array(l),\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given data of size 100 with 10-fold cross validation, the accuracy of the model is about 0.633333334327."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 62.3833, step = 1\n",
      "INFO:tensorflow:Loss for final step: 62.3833.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:03:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:03:54\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.888889, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 161.27, global_step = 1, label/mean = 0.0, loss = 1451.43, prediction/mean = 0.111111\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.14673e+08, step = 2\n",
      "INFO:tensorflow:Loss for final step: 3.14673e+08.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:03:57\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-2\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:03:57\n",
      "INFO:tensorflow:Saving dict for global step 2: accuracy = 1.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 2, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.98354e+07, step = 3\n",
      "INFO:tensorflow:Loss for final step: 4.98354e+07.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:03:59\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-3\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:03:59\n",
      "INFO:tensorflow:Saving dict for global step 3: accuracy = 0.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 4.66599e+06, global_step = 3, label/mean = 0.0, loss = 4.19939e+07, prediction/mean = 1.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-3\n",
      "INFO:tensorflow:Saving checkpoints for 4 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.63131e+08, step = 4\n",
      "INFO:tensorflow:Loss for final step: 3.63131e+08.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-4\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:02\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 1.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 4, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-4\n",
      "INFO:tensorflow:Saving checkpoints for 5 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.10685e+08, step = 5\n",
      "INFO:tensorflow:Loss for final step: 1.10685e+08.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-5\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:04\n",
      "INFO:tensorflow:Saving dict for global step 5: accuracy = 1.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 5, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-5\n",
      "INFO:tensorflow:Saving checkpoints for 6 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.18471e+06, step = 6\n",
      "INFO:tensorflow:Loss for final step: 6.18471e+06.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-6\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:06\n",
      "INFO:tensorflow:Saving dict for global step 6: accuracy = 0.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 2.65961e+06, global_step = 6, label/mean = 0.0, loss = 2.39365e+07, prediction/mean = 1.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-6\n",
      "INFO:tensorflow:Saving checkpoints for 7 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.18628e+08, step = 7\n",
      "INFO:tensorflow:Loss for final step: 2.18628e+08.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-7\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:09\n",
      "INFO:tensorflow:Saving dict for global step 7: accuracy = 1.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 7, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-7\n",
      "INFO:tensorflow:Saving checkpoints for 8 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.46549e+07, step = 8\n",
      "INFO:tensorflow:Loss for final step: 9.46549e+07.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:10\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-8\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:11\n",
      "INFO:tensorflow:Saving dict for global step 8: accuracy = 1.0, accuracy_baseline = 1.0, auc = 1.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 8, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-8\n",
      "INFO:tensorflow:Saving checkpoints for 9 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.5106e+07, step = 9\n",
      "INFO:tensorflow:Loss for final step: 1.5106e+07.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-9\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:13\n",
      "INFO:tensorflow:Saving dict for global step 9: accuracy = 0.444444, accuracy_baseline = 0.555556, auc = 0.5, auc_precision_recall = 0.722222, average_loss = 1.15629e+06, global_step = 9, label/mean = 0.444444, loss = 1.04066e+07, prediction/mean = 1.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-9\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /tmp/tmptOzMhV/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.24732e+08, step = 10\n",
      "INFO:tensorflow:Loss for final step: 1.24732e+08.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-23-02:04:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptOzMhV/model.ckpt-10\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-23-02:04:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.0, accuracy_baseline = 1.0, auc = 0.0, auc_precision_recall = 1.0, average_loss = 6.08789e+06, global_step = 10, label/mean = 1.0, loss = 5.4791e+07, prediction/mean = 0.0\n",
      "0.633333334327\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "data_size = len(training_labels)\n",
    "size = data_size / K\n",
    "total_accuracy = 0\n",
    "for i in range(K):\n",
    "    trs = { k: v[0:(i * size)] + v[(i * size) + size:data_size] for k, v in training_set.items() }\n",
    "    ts = { k: v[(i * size):((i * size) + size)] for k, v in training_set.items() }\n",
    "\n",
    "    trsl = training_labels[0:(i * size)] + training_labels[(i * size) + size:data_size]\n",
    "    tsl = training_labels[(i * size):((i * size) + size)]\n",
    "\n",
    "    model.train(input_fn=input_fn(trs, trsl), steps=1)\n",
    "    result = model.evaluate(input_fn=input_fn(ts, tsl), steps=1)\n",
    "\n",
    "    total_accuracy += result['accuracy']\n",
    "\n",
    "print total_accuracy / K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
